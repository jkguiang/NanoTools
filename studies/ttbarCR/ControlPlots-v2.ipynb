{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import uproot\n",
    "\n",
    "from yahist import Hist1D\n",
    "from yahist.utils import plot_stack\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlob params\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knobs\n",
    "flatten_babies = False\n",
    "use_norm_weight = False\n",
    "use_jet_weights = True\n",
    "baby_ver = 'v6-1-0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_norm_weight and use_jet_weights:\n",
    "    plot_output_dir = '/home/users/aaarora/public_html/controlPlots/plots_w_both/'\n",
    "elif use_norm_weight and not use_jet_weights:\n",
    "    plot_output_dir = '/home/users/aaarora/public_html/controlPlots/plots_w_only_norm/'\n",
    "elif not use_norm_weight and use_jet_weights:\n",
    "    plot_output_dir = '/home/users/aaarora/public_html/controlPlots/plots_w_only_jet/'\n",
    "else:\n",
    "    plot_output_dir = '/home/users/aaarora/public_html/controlPlots/plots_w_neither/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for reading files\n",
    "path_to_mc_TTJets = \"/hadoop/cms/store/user/jguiang/ttbarCR/babies/TTJets/\"\n",
    "mc_dirs_TTJets = [f.path for f in os.scandir(path_to_mc_TTJets) if f.is_dir() and baby_ver in f.path]\n",
    "def mc_files_TTJets(i):\n",
    "    n_events_TTJets = uproot.open(mc_dirs_TTJets[i] + '/baby.root').get(\"n_events\").allvalues[1]\n",
    "    df = uproot.open(mc_dirs_TTJets[i] + '/baby.root').get(\"tree\").pandas.df(flatten=flatten_babies)\n",
    "    if ('DiLept_' in mc_dirs_TTJets[i]):\n",
    "        df.insert(1,'xsec',87.3)\n",
    "        df.insert(2,'n_events',n_events_TTJets)\n",
    "    elif ('SingleLeptFromT_' in mc_dirs_TTJets[i]):\n",
    "        df.insert(1,'xsec',182.7)\n",
    "        df.insert(2,'n_events',n_events_TTJets)\n",
    "    elif ('SingleLeptFromTbar_' in mc_dirs_TTJets[i]):\n",
    "        df.insert(1,'xsec',182.7)\n",
    "        df.insert(2,'n_events',n_events_TTJets)\n",
    "                                    \n",
    "    if ('Summer16' in mc_dirs_TTJets[i]):\n",
    "        df.insert(3,'int_lumi',35920)\n",
    "        df.insert(4,'year',2016)\n",
    "    elif ('Fall17' in mc_dirs_TTJets[i]): \n",
    "        df.insert(3,'int_lumi',41530)\n",
    "        df.insert(4,'year',2017)\n",
    "    elif ('Autumn18' in mc_dirs_TTJets[i]):\n",
    "        df.insert(3,'int_lumi',59740)\n",
    "        df.insert(4,'year',2018)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mc_ST = \"/hadoop/cms/store/user/jguiang/ttbarCR/babies/ST/\"\n",
    "mc_dirs_ST = [f.path for f in os.scandir(path_to_mc_ST) if f.is_dir() and baby_ver in f.path]\n",
    "def mc_files_ST(i):\n",
    "    n_events_ST = uproot.open(mc_dirs_ST[i] + '/baby.root').get(\"n_events\").allvalues[1]\n",
    "    df = uproot.open(mc_dirs_ST[i] + '/baby.root').get(\"tree\").pandas.df(flatten=flatten_babies)\n",
    "    if ('s-channel' in mc_dirs_ST[i]):\n",
    "        df.insert(1,'xsec',3.7)\n",
    "        df.insert(2,'n_events',n_events_ST)\n",
    "    elif ('t-channel_antitop' in mc_dirs_ST[i]):\n",
    "        df.insert(1,'xsec',80.95)\n",
    "        df.insert(2,'n_events',n_events_ST)\n",
    "    elif ('t-channel_top' in mc_dirs_ST[i]):\n",
    "        df.insert(1,'xsec',136.02)\n",
    "        df.insert(2,'n_events',n_events_ST)\n",
    "    elif ('tW_antitop' in mc_dirs_ST[i]):\n",
    "        df.insert(1,'xsec',19.6)\n",
    "        df.insert(2,'n_events',n_events_ST)\n",
    "    elif ('tW_top' in mc_dirs_ST[i]):\n",
    "        df.insert(1,'xsec',19.6)\n",
    "        df.insert(2,'n_events',n_events_ST)\n",
    "        \n",
    "    if ('Summer16' in mc_dirs_ST[i]):\n",
    "        df.insert(3,'int_lumi',35920)\n",
    "        df.insert(4,'year',2016)\n",
    "    elif ('Fall17' in mc_dirs_ST[i]):\n",
    "        df.insert(3,'int_lumi',41530)\n",
    "        df.insert(4,'year',2017)\n",
    "    elif ('Autumn18' in mc_dirs_ST[i]):\n",
    "        df.insert(3,'int_lumi',59740)\n",
    "        df.insert(4,'year',2018)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mc_VV = \"/hadoop/cms/store/user/jguiang/ttbarCR/babies/VV/\"\n",
    "mc_dirs_VV = [f.path for f in os.scandir(path_to_mc_VV) if f.is_dir() and baby_ver in f.path]\n",
    "def mc_files_VV(i):\n",
    "    n_events_VV = uproot.open(mc_dirs_VV[i] + '/baby.root').get(\"n_events\").allvalues[1]\n",
    "    df = uproot.open(mc_dirs_VV[i] + '/baby.root').get(\"tree\").pandas.df(flatten=flatten_babies)\n",
    "    if ('WWTo2L2Nu_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',12.18)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('WWToLNuQQ_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',50.00)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('WZTo1L1Nu2Q_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',10.74)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('WZTo1L3Nu_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',3.05)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('WZTo2L2Q_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',5.60)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('WZTo3LNu_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',4.43)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('ZZTo2L2Nu_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',0.56)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('ZZTo2L2Q_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',3.22)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('ZZTo2Q2Nu_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',4.73)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "    elif ('ZZTo4L_' in mc_dirs_VV[i]):\n",
    "        df.insert(1,'xsec',1.25)\n",
    "        df.insert(2,'n_events',n_events_VV)\n",
    "        \n",
    "    if ('Summer16' in mc_dirs_VV[i]):\n",
    "        df.insert(3,'int_lumi',35920)\n",
    "        df.insert(4,'year',2016)\n",
    "    elif ('Fall17' in mc_dirs_VV[i]):\n",
    "        df.insert(3,'int_lumi',41530)\n",
    "        df.insert(4,'year',2017)\n",
    "    elif ('Autumn18' in mc_dirs_VV[i]):\n",
    "        df.insert(3,'int_lumi',59740)\n",
    "        df.insert(4,'year',2018)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mc_TTV = \"/hadoop/cms/store/user/jguiang/ttbarCR/babies/TTV/\"\n",
    "mc_dirs_TTV = [f.path for f in os.scandir(path_to_mc_TTV) if f.is_dir() and baby_ver in f.path]\n",
    "def mc_files_TTV(i):\n",
    "    n_events_TTV = uproot.open(mc_dirs_TTV[i] + '/baby.root').get(\"n_events\").allvalues[1]\n",
    "    df = uproot.open(mc_dirs_TTV[i] + '/baby.root').get(\"tree\").pandas.df(flatten=flatten_babies)\n",
    "    if ('TTWJetsToLNu_' in mc_dirs_TTV[i]):\n",
    "        df.insert(1,'xsec',0.20)\n",
    "        df.insert(2,'n_events',n_events_TTV)\n",
    "    elif ('TTWJetsToQQ_' in mc_dirs_TTV[i]):\n",
    "        df.insert(1,'xsec',0.40)\n",
    "        df.insert(2,'n_events',n_events_TTV)\n",
    "    elif ('TTZToLLNuNu_' in mc_dirs_TTV[i]):\n",
    "        df.insert(1,'xsec',0.25)\n",
    "        df.insert(2,'n_events',n_events_TTV)\n",
    "    elif ('TTZToQQ_' in mc_dirs_TTV[i]):\n",
    "        df.insert(1,'xsec',0.53)\n",
    "        df.insert(2,'n_events',n_events_TTV)\n",
    "        \n",
    "    if ('Summer16' in mc_dirs_TTV[i]):\n",
    "        df.insert(3,'int_lumi',35920)\n",
    "        df.insert(4,'year',2016)\n",
    "    elif ('Fall17' in mc_dirs_TTV[i]):\n",
    "        df.insert(3,'int_lumi',41530)\n",
    "        df.insert(4,'year',2017)\n",
    "    elif ('Autumn18' in mc_dirs_TTV[i]):\n",
    "        df.insert(3,'int_lumi',59740)\n",
    "        df.insert(4,'year',2018)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mc_VJets = \"/hadoop/cms/store/user/jguiang/ttbarCR/babies/VJets/\"\n",
    "mc_dirs_VJets = [f.path for f in os.scandir(path_to_mc_VJets) if f.is_dir() and baby_ver in f.path]\n",
    "def mc_files_VJets(i):\n",
    "    n_events_VJets = uproot.open(mc_dirs_VJets[i] + '/baby.root').get(\"n_events\").allvalues[1]\n",
    "    df = uproot.open(mc_dirs_VJets[i] + '/baby.root').get(\"tree\").pandas.df(flatten=flatten_babies)\n",
    "    if ('DYJetsToLL_' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',6021)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W1JetsToLNu_NuPt-200_' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',2.36)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W1JetsToLNu_Tu' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',11752)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W2JetsToLNu_NuPt-200_' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',4.95)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W2JetsToLNu_Tu' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',3841)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W3JetsToLNu_NuPt-200_' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',4.94)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W3JetsToLNu_Tu' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',1160)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W4JetsToLNu_NuPt-200_' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',8.83)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "    elif ('W4JetsToLNu_Tu' in mc_dirs_VJets[i]):\n",
    "        df.insert(1,'xsec',600)\n",
    "        df.insert(2,'n_events',n_events_list_VJets[i])\n",
    "        \n",
    "    if ('Summer16' in mc_dirs_VJets[i]):\n",
    "        df.insert(3,'int_lumi',35920)\n",
    "        df.insert(4,'year',2016)\n",
    "    elif ('Fall17' in mc_dirs_VJets[i]):\n",
    "        df.insert(3,'int_lumi',41530)\n",
    "        df.insert(4,'year',2017)\n",
    "    elif ('Autumn18' in mc_dirs_VJets[i]):\n",
    "        df.insert(3,'int_lumi',59740)\n",
    "        df.insert(4,'year',2018)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"/hadoop/cms/store/user/jguiang/ttbarCR/babies/MuonEG/\"\n",
    "data_dirs = [f.path for f in os.scandir(path_to_data) if f.is_dir() and baby_ver in f.path]\n",
    "def data_files(i):\n",
    "    df = uproot.open(data_dirs[i] + '/baby.root').get(\"tree\").pandas.df(flatten=flatten_babies)\n",
    "    if ('2016' in data_dirs[i]):\n",
    "        df.insert(1,'year',2016)\n",
    "    elif ('2017' in data_dirs[i]):\n",
    "        df.insert(1,'year',2017)\n",
    "    elif ('2018' in data_dirs[i]):\n",
    "        df.insert(1,'year',2018)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list w/ functions above\n",
    "mc_list_TTJets = list()\n",
    "for i in tqdm(range(len(mc_dirs_TTJets)),desc='Appending..'):\n",
    "    mc_list_TTJets.append(mc_files_TTJets(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_list_ST = list()\n",
    "for i in tqdm(range(len(mc_dirs_ST)),desc='Appending..'):\n",
    "    try:\n",
    "        mc_list_ST.append(mc_files_ST(i))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_list_VV = list()\n",
    "for i in tqdm(range(len(mc_dirs_VV)),desc='Appending..'):\n",
    "    try:\n",
    "        mc_list_VV.append(mc_files_VV(i))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_list_TTV = list()\n",
    "for i in tqdm(range(len(mc_dirs_TTV)),desc='Appending..'):\n",
    "    mc_list_TTV.append(mc_files_TTV(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_list_VJets = list()\n",
    "for i in tqdm(range(len(mc_dirs_VJets)),desc='Appending..'):\n",
    "    try:\n",
    "        mc_list_VJets.append(mc_files_VJets(i))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = list()\n",
    "for i in tqdm(range(len(data_dirs)),desc='Appending..'):\n",
    "    data_list.append(data_files(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to make df\n",
    "mc_TTJets = pd.concat(mc_list_TTJets)\n",
    "mc_ST = pd.concat(mc_list_ST)\n",
    "mc_VV = pd.concat(mc_list_VV)\n",
    "mc_TTV = pd.concat(mc_list_TTV)\n",
    "#mc_VJets = pd.concat(mc_list_VJets)\n",
    "data = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_TTJets = mc_TTJets.drop_duplicates(subset=['leading_lep_pt', 'trailing_lep_pt'])\n",
    "mc_ST = mc_ST.drop_duplicates(subset=['leading_lep_pt', 'trailing_lep_pt'])\n",
    "mc_VV = mc_VV.drop_duplicates(subset=['leading_lep_pt', 'trailing_lep_pt'])\n",
    "mc_TTV = mc_TTV.drop_duplicates(subset=['leading_lep_pt', 'trailing_lep_pt'])\n",
    "#mc_VJets = mc_VJets.drop_duplicates(subset=['leading_lep_pt', 'trailing_lep_pt'])\n",
    "data = data.drop_duplicates(subset=['leading_lep_pt', 'trailing_lep_pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc_TTJets.to_pickle('mc_TTJets_flat.pickle')\n",
    "# mc_ST.to_pickle('mc_ST_flat.pickle')\n",
    "# mc_VV.to_pickle('mc_VV_flat.pickle')\n",
    "# mc_TTV.to_pickle('mc_TTV_flat.pickle')\n",
    "# mc_VJets.to_pickle('mc_VJets_flat.pickle')\n",
    "# data.to_pickle('data_flat.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc_TTJets = pd.read_pickle('/hadoop/cms/store/user/jguiang/ttbarCR/babies/pickles/mc_TTJets.pickle')\n",
    "# mc_ST = pd.read_pickle('/hadoop/cms/store/user/jguiang/ttbarCR/babies/pickles/mc_ST.pickle')\n",
    "# mc_VV = pd.read_pickle('/hadoop/cms/store/user/jguiang/ttbarCR/babies/pickles/mc_VV.pickle')\n",
    "# mc_TTV = pd.read_pickle('/hadoop/cms/store/user/jguiang/ttbarCR/babies/pickles/mc_TTV.pickle')\n",
    "# mc_VJets = pd.read_pickle('/hadoop/cms/store/user/jguiang/ttbarCR/babies/pickles/mc_VJets.pickle')\n",
    "# data = pd.read_pickle('/hadoop/cms/store/user/jguiang/ttbarCR/babies/pickles/data_MuonEG.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_TTV_VV = pd.concat([mc_TTV, mc_VV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ = 2017\n",
    "mc_c_TTJets = mc_TTJets[mc_TTJets['year']==year_]\n",
    "mc_c_ST = mc_ST[mc_ST['year']==year_]\n",
    "mc_c_TTV_VV = mc_TTV_VV[mc_TTV_VV['year']==year_]\n",
    "#mc_c_VJets = mc_VJets[mc_VJets['year']==year_]\n",
    "data_c = data[data['year']==year_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'TTJets': mc_c_TTJets,'ST': mc_c_ST,'TTV+VV': mc_c_TTV_VV}#,'VJets': mc_c_VJets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_weights(df):\n",
    "    return np.array(df.gen_weight * df.xsec * df.int_lumi * df.mc_tight_btag_weight * df.mc_weight / df.n_events)\n",
    "def build_weights_dict(use_norm_weight, use_jet_weights):\n",
    "    weights_dict = dict()\n",
    "    normalization_weight = 1.0\n",
    "    for name in df_dict:\n",
    "        weights_dict[name] = primary_weights(df_dict[name])\n",
    "    if use_norm_weight:\n",
    "        normalization_weight = len(data_c) / sum([sum(weights_dict[v]) for v in weights_dict])\n",
    "        for name in df_dict:\n",
    "            weights_dict[name] *= normalization_weight\n",
    "    if use_jet_weights:\n",
    "        jet_weights = np.nan_to_num(np.divide(np.histogram(data_c.num_jets,bins=np.linspace(0,50,51))[0], \n",
    "                                              sum([np.histogram(df_dict[name].num_jets,bins=np.linspace(0,50,51),\n",
    "                                                           weights=weights_dict[name])[0] for name in df_dict])),nan=1)\n",
    "        for name in df_dict:\n",
    "            df_dict[name]['jet_weights'] = df_dict[name].num_jets.apply(lambda x : jet_weights[x])\n",
    "        for name in df_dict:\n",
    "            weights_dict[name] *= df_dict[name].jet_weights\n",
    "    return weights_dict, normalization_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict, integral_w = build_weights_dict(use_norm_weight, use_jet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ax1(ax1):\n",
    "    \"\"\"Format main 1D hist\"\"\"\n",
    "    # Sort legend\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    # Sort alphabetically\n",
    "    abc_labels, abc_handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "    abc_labels, abc_handles = list(abc_labels), list(abc_handles)\n",
    "    # Additional, manual sorting\n",
    "    sorted_handles = abc_handles\n",
    "    sorted_labels = abc_labels\n",
    "    for i, label in enumerate(abc_labels):\n",
    "        # Guarantee data is on top\n",
    "        if \"Data\" in label:\n",
    "            sorted_labels.insert(0, sorted_labels.pop(i))\n",
    "            sorted_handles.insert(0, sorted_handles.pop(i))\n",
    "        # Guarantee TTJets is below data\n",
    "        elif \"TTJets\" in label:\n",
    "            if \"Data\" in sorted_labels[0]:\n",
    "                sorted_labels.insert(1, sorted_labels.pop(i))\n",
    "                sorted_handles.insert(1, sorted_handles.pop(i))\n",
    "            else:\n",
    "                sorted_labels.insert(0, sorted_labels.pop(i))\n",
    "                sorted_handles.insert(0, sorted_handles.pop(i))\n",
    "        # Guarantee text is on the bottom\n",
    "        elif \"scaled\\\\hspace{0.25}\" in label:\n",
    "            sorted_labels.append(sorted_labels.pop(i))\n",
    "            sorted_handles.append(sorted_handles.pop(i))\n",
    "    # Plot new labels/handles\n",
    "    sorted_labels = tuple(sorted_labels)\n",
    "    sorted_handles = tuple(sorted_handles)\n",
    "    ax1.legend(sorted_handles, sorted_labels, title=r'$\\bf{}$'.format(str(year_)),title_fontsize=15)\n",
    "    ax1.text(\n",
    "        0.0, \n",
    "        1.01,\n",
    "        \"CMS\", \n",
    "        horizontalalignment=\"left\", \n",
    "        verticalalignment=\"bottom\", \n",
    "        transform=ax1.transAxes, \n",
    "        weight=\"bold\", \n",
    "        size=18\n",
    "    )\n",
    "    ax1.text(\n",
    "        0.09, \n",
    "        1.01, \n",
    "        \"Preliminary\", \n",
    "        horizontalalignment=\"left\", \n",
    "        verticalalignment=\"bottom\", \n",
    "        transform=ax1.transAxes, \n",
    "        style=\"italic\", \n",
    "        size=18\n",
    "    )\n",
    "    ax1.text(\n",
    "        0.99, \n",
    "        1.01,\n",
    "        \"%0.1f fb${}^\\mathregular{-1}$ (13 TeV)\" % (mc_c_TTJets.int_lumi.iloc[0] / 1000), \n",
    "        horizontalalignment='right', \n",
    "        verticalalignment='bottom', \n",
    "        transform = ax1.transAxes, \n",
    "        size=\"x-large\"\n",
    "    )\n",
    "    ax1.set_ylabel(\"Events\")\n",
    "    ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax1.yaxis.set_minor_locator(AutoMinorLocator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ax2(ax2, xlabel, ylabel=r\"$\\frac{Data}{MC}$\"):\n",
    "    \"\"\"Format ratio plot\"\"\"\n",
    "    ax2.axhline(y=1, color=\"k\", linestyle=\"--\", alpha=0.75, linewidth=0.75)\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    ax2.set_ylabel(ylabel,fontsize=18)\n",
    "    ax2.set_ylim(0.3,1.7)\n",
    "    ax2.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax2.xaxis.set_minor_locator(AutoMinorLocator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typical_hist(branch_name, bins, hist_axes, ratio_axes):\n",
    "    color_list = ['gold', 'steelblue', 'red', 'green', 'purple']\n",
    "    count = 0\n",
    "    plot_list = list()\n",
    "    for name, df in df_dict.items():\n",
    "        plot_list.append(\n",
    "        Hist1D(\n",
    "            df[branch_name],\n",
    "            weights = weights_dict[name],bins=bins,\n",
    "            label=name + ' ['+str(round(sum(weights_dict[name]))) + ']',\n",
    "            color=color_list[count])\n",
    "        )\n",
    "        count += 1\n",
    "    # Data plot\n",
    "    data_p = Hist1D(\n",
    "        data_c[branch_name],\n",
    "        bins=bins,\n",
    "        label='Data ['+str(len(data_c))+']',\n",
    "        color='black'\n",
    "    )\n",
    "    # Stacked hist\n",
    "    plot_stack(plot_list, ax=hist_axes, histtype='bar')\n",
    "    # Data plot\n",
    "    data_p.plot(ax=hist_axes, show_errors=True)\n",
    "    # Ratio plot\n",
    "    (data_p/(sum(plot_list))).plot(ax=ratio_axes, show_errors=True, label='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_a_typical_hist(branch_name_1, branch_name_2, bins, hist_axes, ratio_axes):\n",
    "    color_list = ['gold', 'steelblue', 'red', 'green', 'purple']\n",
    "    count = 0\n",
    "    plot_list = list()\n",
    "    for name, df in df_dict.items():\n",
    "        plot_list.append(\n",
    "        Hist1D(\n",
    "            abs(df[branch_name_1] - df[branch_name_2]),\n",
    "            weights = weights_dict[name],bins=bins,\n",
    "            label=name + ' ['+str(round(sum(weights_dict[name]))) + ']',\n",
    "            color=color_list[count])\n",
    "        )\n",
    "        count += 1\n",
    "    # Data plot\n",
    "    data_p = Hist1D(\n",
    "        abs(data_c[branch_name_1] - data_c[branch_name_2]) ,\n",
    "        bins=bins,\n",
    "        label='Data ['+str(len(data_c))+']',\n",
    "        color='black'\n",
    "    )\n",
    "    # Stacked hist\n",
    "    plot_stack(plot_list, ax=hist_axes, histtype='bar')\n",
    "    # Data plot\n",
    "    data_p.plot(ax=hist_axes, show_errors=True)\n",
    "    # Ratio plot\n",
    "    (data_p/(sum(plot_list))).plot(ax=ratio_axes, show_errors=True, label='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x----------------------------------------------PLOTS BEGIN HERE----------------------------------------------x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip not $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"jet_eta\", bins=np.linspace(-3,3,10), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Jet $\\eta$\")\n",
    "plt.savefig(plot_output_dir + 'jet_eta.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip not $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"jet_phi\", bins=np.linspace(-np.pi,np.pi,10), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Jet $\\phi$\")\n",
    "plt.savefig(plot_output_dir + 'jet_phi.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"met\", bins=np.linspace(0,350,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=\"MET\")\n",
    "plt.savefig(plot_output_dir + 'met.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"vbs_dijet_mass\", bins=np.linspace(0,2000,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=\"$M_{jj}$\")\n",
    "plt.savefig(plot_output_dir + 'vbs_dijet_mass.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"dilep_mass\", bins=np.linspace(0,500,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=\"$M_{\\ell\\ell}$\")\n",
    "plt.savefig(plot_output_dir + 'dilep_mass.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"num_jets\", bins=np.linspace(0,12,13), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=\"Number of Jets\")\n",
    "plt.savefig(plot_output_dir + 'num_jets.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"leading_vbs_jet_P\", bins=np.linspace(0,2500,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Leading VBS Jet P\")\n",
    "plt.savefig(plot_output_dir + 'leading_vbs_jet_P.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"trailing_vbs_jet_P\", bins=np.linspace(0,2500,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Trailing VBS Jet P\")\n",
    "plt.savefig(plot_output_dir + 'trailing_vbs_jet_P.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"leading_vbs_jet_pt\", bins=np.linspace(0,1000,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Leading VBS Jet $p_T$\")\n",
    "plt.savefig(plot_output_dir + 'leading_vbs_jet_pt.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"trailing_vbs_jet_pt\", bins=np.linspace(0,600,11), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Trailing VBS Jet $p_T$\")\n",
    "plt.savefig(plot_output_dir + 'trailing_vbs_jet_pt.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"leading_vbs_jet_eta\", bins=np.linspace(-5,5,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Leading VBS Jet $\\eta$\")\n",
    "plt.savefig(plot_output_dir + 'leading_vbs_jet_eta.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"trailing_vbs_jet_eta\", bins=np.linspace(-5,5,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Trailing VBS Jet $\\eta$\")\n",
    "plt.savefig(plot_output_dir + 'trailing_vbs_jet_eta.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"leading_vbs_jet_phi\", bins=np.linspace(-np.pi,np.pi,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Leading VBS Jet $\\phi$\")\n",
    "plt.savefig(plot_output_dir + 'leading_vbs_jet_phi.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"trailing_vbs_jet_phi\", bins=np.linspace(-np.pi,np.pi,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Trailing VBS Jet $\\phi$\")\n",
    "plt.savefig(plot_output_dir + 'trailing_vbs_jet_phi.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"leading_lep_pt\", bins=np.linspace(0,300,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Leading Lepton $p_T$\")\n",
    "plt.savefig(plot_output_dir + 'leading_lep_pt.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"trailing_lep_pt\", bins=np.linspace(0,300,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Trailing Lepton $p_T$\")\n",
    "plt.savefig(plot_output_dir + 'trailing_lep_pt.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"leading_lep_eta\", bins=np.linspace(-2.5,2.5,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Leading Lepton $\\eta$\")\n",
    "plt.savefig(plot_output_dir + 'leading_lep_eta.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"trailing_lep_eta\", bins=np.linspace(-2.5,2.5,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Trailing Lepton $\\eta$\")\n",
    "plt.savefig(plot_output_dir + 'trailing_lep_eta.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"leading_lep_phi\", bins=np.linspace(-np.pi,np.pi,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Leading Lepton $\\phi$\")\n",
    "plt.savefig(plot_output_dir + 'leading_lep_phi.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "typical_hist(\"trailing_lep_phi\", bins=np.linspace(-np.pi,np.pi,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"Trailing Lepton $\\phi$\")\n",
    "plt.savefig(plot_output_dir + 'trailing_lep_phi.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "not_a_typical_hist(\"leading_vbs_jet_eta\", \"trailing_vbs_jet_eta\", bins=np.linspace(0,3*np.pi,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"VBS Jets $|d\\eta$|\")\n",
    "plt.savefig(plot_output_dir + 'vbs_jet_deta.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip $flatten_babies\n",
    "# Stacked hist\n",
    "fig, (ax1, ax2) = plt.subplots(2,sharex=True,figsize=(10,10),gridspec_kw=dict(height_ratios=[5, 2]))\n",
    "not_a_typical_hist(\"leading_vbs_jet_phi\", \"trailing_vbs_jet_phi\", bins=np.linspace(0,2*np.pi,21), hist_axes=ax1, ratio_axes=ax2)\n",
    "\n",
    "# Dummy plot to add text to legend\n",
    "ax1.plot(\n",
    "    [],[],' ',\n",
    "    label=r\"$\\bf{MC\\hspace{0.25} scaled\\hspace{0.25} by\\hspace{0.25} %0.2f}$\" % integral_w\n",
    ")\n",
    "format_ax1(ax1)\n",
    "format_ax2(ax2, xlabel=r\"VBS Jets $|d\\phi$|\")\n",
    "plt.savefig(plot_output_dir + 'vbs_jet_dphi.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
